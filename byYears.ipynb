{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+-----------------------+\n",
      "|year|SENDER_SITE_LOC_ID|sum(ITEMS_TOTAL_AMOUNT)|\n",
      "+----+------------------+-----------------------+\n",
      "|2017|             15705|             1059237974|\n",
      "|2017|             15801|            12531848256|\n",
      "|2017|              8627|            28521692304|\n",
      "|2017|             15793|           748974778302|\n",
      "|2017|              7597|              524884448|\n",
      "|2018|              7597|             2254851640|\n",
      "|2017|             15695|               12979272|\n",
      "+----+------------------+-----------------------+\n",
      "\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "    SENDER_SITE_LOC_ID  sum(ITEMS_TOTAL_AMOUNT)  year\n",
      "0                15705             1.059238e+09  2017\n",
      "1                15801             1.253185e+10  2017\n",
      "2                 8627             2.852169e+10  2017\n",
      "3                15793             7.489748e+11  2017\n",
      "4                 7597             5.248844e+08  2017\n",
      "5                 7597             2.254852e+09  2018\n",
      "6                15695             1.297927e+07  2017\n",
      "7                15705                      NaN  2018\n",
      "8                15801                      NaN  2018\n",
      "9                 8627                      NaN  2018\n",
      "10               15793                      NaN  2018\n",
      "11               15695                      NaN  2018\n",
      "    SENDER_SITE_LOC_ID  sum(ITEMS_TOTAL_AMOUNT)  year\n",
      "0                15705             1.059238e+09  2017\n",
      "1                15801             1.253185e+10  2017\n",
      "2                 8627             2.852169e+10  2017\n",
      "3                15793             7.489748e+11  2017\n",
      "4                 7597             5.248844e+08  2017\n",
      "5                 7597             2.254852e+09  2018\n",
      "6                15695             1.297927e+07  2017\n",
      "7                15705             0.000000e+00  2018\n",
      "8                15801             0.000000e+00  2018\n",
      "9                 8627             0.000000e+00  2018\n",
      "10               15793             0.000000e+00  2018\n",
      "11               15695             0.000000e+00  2018\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pyspark\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "#################################             FUNCTIONNALITY             ########################################\n",
    "\n",
    "\n",
    "# this programs reads a csv file from the TBF110. \n",
    "\n",
    "# The program counts the sum ITEMS_TOTAL_AMOUNT for each sender_id and each year\n",
    "\n",
    "# It creates 0 values for the non existing dates for each sender_id and stores it in a csv for later visualizing\n",
    "\n",
    "\n",
    "#################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "# Set up the spark session\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"spark://spark-master:7077\") \\\n",
    "   .appName(\"sumbyyears\") \\\n",
    "   .config(conf = pyspark.SparkConf()) \\\n",
    "   .getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "# Read the csv File\n",
    "\n",
    "df1 = spark.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('../sparkJup/romain.csv')\n",
    "\n",
    "\n",
    "\n",
    "dftest = df1.groupby(\"year\",\"SENDER_SITE_LOC_ID\").agg(sum('ITEMS_TOTAL_AMOUNT'))\n",
    "dftest.show()\n",
    "\n",
    "dfYear = dftest.toPandas()\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "\n",
    "# Remove the duplicates for sender_id\n",
    "\n",
    "senderId = pd.unique(dfYear['SENDER_SITE_LOC_ID'].values)\n",
    "\n",
    "\n",
    "# A table with all the dates which occur one time\n",
    "\n",
    "dateByYear = pd.unique(dfYear['year'].values)\n",
    "\n",
    "\n",
    "# Set up the table length\n",
    "\n",
    "lenDateByYear = len(dateByYear)\n",
    "lenSenderId = len(senderId)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This loop is used to create some rows for sender_id which did not have all the dates\n",
    "# Example sender_id = 1 year = 2017 dateByYear=[2017,2018]\n",
    "# A new row is created to have sender_id = 1 year 2017 and sender_id = 1 year = 2018\n",
    "# This is compulsory for creating visualization\n",
    "\n",
    "while i < lenSenderId:\n",
    "    for j in range(lenDateByYear):\n",
    "        if i+j < lenSenderId + lenDateByYear:\n",
    "            dftemp = dfYear.loc[dfYear['SENDER_SITE_LOC_ID'].isin([senderId[i]]) & dfYear['year'].isin([dateByYear[j]])]\n",
    "            #print(senderId[i])\n",
    "            #print(dateByYear[j])\n",
    "            if (dftemp.empty == True):\n",
    "                df3 = pd.DataFrame(np.array([[dateByYear[j],senderId[i]]]), columns=['year','SENDER_SITE_LOC_ID'])\n",
    "                dfYear = dfYear.append(df3, ignore_index=True)\n",
    "#                #print(dfsum['SENDER_SITE_LOC_ID'][i])\n",
    "#                #print(dfsum['year'][i])\n",
    "#                print(tab2[j])\n",
    "#                print('not ok')\n",
    "            else :\n",
    "                print('ok')\n",
    "                #print(dfsum['SENDER_SITE_LOC_ID'][i])\n",
    "                #print(dfsum['year'][i])\n",
    "                #print(tab2[j])\n",
    "\n",
    "\n",
    "        else:\n",
    "            if(dfsum['year'][i+j - 1] != dateByYear[len(dateByYear)-1]):\n",
    "                #print('make something')\n",
    "                df3 = pd.DataFrame(np.array([[dateByYear[j],senderId[i]]]), columns=['year','SENDER_SITE_LOC_ID'])\n",
    "                dfYear = dfYear.append(df3, ignore_index=True)\n",
    "    i = i + 1\n",
    "\n",
    "\n",
    "print(dfYear)\n",
    "\n",
    "\n",
    "# Replace the values which are NaN by 0\n",
    "\n",
    "dfYear= dfYear.fillna(0)\n",
    "\n",
    "print(dfYear)\n",
    "\n",
    "\n",
    "# Save to a csv File\n",
    "\n",
    "dfYear.to_csv('sumbyyears.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
